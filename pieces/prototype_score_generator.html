<!DOCTYPE html>
<html>
<head>
<title>Prototype Score Generator</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script src="https://cdnjs.cloudflare.com/ajax/libs/dat-gui/0.7.1/dat.gui.js"></script>
<script src="https://code.jquery.com/jquery-3.6.0.js" integrity="sha256-H+K7U5CnXl1h5ywQfKtSj8PCmoN9aaq30gDh27Xc0jk=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.1/p5.js" integrity="sha512-4P0ZJ49OMXe3jXT+EsEaq82eNwFeyYL81LeHGzGcEhowFbTqeQ80q+NEkgsE8tHPs6aCqvi7U+XWliAjDmT5Lg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/sprintf/1.1.2/sprintf.js" integrity="sha512-dY9NsJoe4eisOR4ZtU0WaFNOxGcGZMfaviwSYHoiiEXvC6QLBsOOVsv3uY+5lEvuRtGTATg7usKQGajlDWSo7Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/91/three.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/ace/1.9.6/ace.js" integrity="sha512-czfWedq9cnMibaqVP2Sw5Aw1PTTabHxMuTOkYkL15cbCYiatPIbxdV0zwhfBZKNODg0zFqmbz8f7rKmd6tfR/Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tinycolor/1.4.2/tinycolor.js" integrity="sha512-lFoTu1RScb5+1ossorzeg5Ny23ak1W44WSkETDK8z5uX7r0uBRvK73XHZl5pE0XoOF1ET36BET/5FLcuiCUhhQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="CsoundAudioNode.js"></script>
<script src="CsoundAC.js"></script>
<script src="silencio/js/TrackballControls.js"></script>
<script src="silencio/js/tinycolor.js"></script>
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="icon" href="data:,">
<style>
</style>
</head>
<body id="body" class="w3-medium" style="height:100vh;">
    <div class="w3-bar w3-dark-grey" style="position:fixed;">    
        <ul class = "menu">
            <li id="menu_item_play" class="w3-btn">Play/stop</li>
            <li id="menu_item_fullscreen" class="w3-btn">Full screen</li>
            <li id="menu_item_settings" class="w3-btn">Settings</li>
            <li id="menu_item_about" class="w3-btn">About</li>
        </ul>
    </div>
    <canvas id="display" class="w3-container" style="background-color:black;height:100%;margin:0;padding:0;">
    </canvas>
    <div id="about_view" class="w3-container" style="position:absolute;top:70px;z-index:3;background:transparent;color:rgba(102,205,170,.75);">
<h1>Prototype Score Generator</h1>
<h3>Michael Gogins<br>
September 2022</h3>

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br/>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>

<p>This is an online piece of electroacoustic music, rendered in high-resolution audio. It will play indefinitely, never ending, always changing. Animated visuals influenced by the music, adapted from <a href="https://www.shadertoy.com/view/ls3Sz4"><b>Neon Music Reaction</b></a> by <a href="https://www.shadertoy.com/user/ciberxtrem">ciberextrem</a>, which has the same license, accompany my music. There are controls you can play with. If you like your settings, save them.

<ul>
<li>To view Csound and JavaScript notifications, use your browser menu to view the JavaScript console.
<li>To view the source code of this piece, use your browser menu to view the page source.
<li>To inspect or debug the code of this piece as it runs, use your browser menu to open the developer tools.
</ul>

<p>This piece can be used as a template for creating new pieces of this type.

<p>Please report any problems you have playing this piece, or any ideas for enhancements, at <a href="https://github.com/gogins/cloud-music/issues">cloud-music issues></a>.
<p>
<a href="http://michaelgogins.tumblr.com">
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Calque_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
     width="36" height="36" viewBox="0 0 256 256" enable-background="new 0 0 256 256" xml:space="preserve">
<g>
    <g>
        <g>
            <rect x="0.24" y="0.167" fill="#314358" width="255.52" height="256"/>
        </g>
    </g>
    <g>
        <path fill="#FFFFFF" d="M168.08,170.918c-2.969,1.416-8.647,2.648-12.881,2.754c-12.783,0.342-15.264-8.979-15.367-15.736v-49.705
            h32.065V84.055h-31.954V43.382c0,0-23.008,0-23.383,0c-0.385,0-1.057,0.337-1.152,1.192c-1.368,12.448-7.192,34.296-31.416,43.032
            v20.624h16.16v52.167c0,17.863,13.176,43.24,47.959,42.641c11.736-0.201,24.77-5.113,27.648-9.354L168.08,170.918"/>
    </g>
</g>
</svg>

</a>
    </div>
    <textarea id="csd" cols=80 rows=24 style="display:none;">
<CsoundSynthesizer>
<CsLicense>
"Oblivion,"" by Astor Piazzola
Arranged for Csound by Michael Gogins
</CsLicense>
<CsOptions>
-+msg_color=0 -odac -m195 -d
</CsOptions>
<CsInstruments>

sr = 48000
ksmps = 128
nchnls = 2
0dbfs = 1

gi_ampmidicurve_dynamic_range init .375
gi_ampmidicurve_exponent init 5

prealloc "ZakianFlute", 4
prealloc "Guitar", 4
prealloc "Harpsichord", 4
prealloc "YiString", 4
prealloc "Bower", 4

connect "Guitar", "outleft", "ReverbSC", "inleft"
connect "Guitar", "outleft", "ReverbSC", "inleft"
connect "ZakianFlute", "outleft", "ReverbSC", "inleft"
connect "ZakianFlute", "outleft", "ReverbSC", "inleft"
connect "Harpsichord", "outleft", "ReverbSC", "inleft"
connect "Harpsichord", "outright", "ReverbSC", "inright"
connect "YiString", "outleft", "ReverbSC", "inleft"
connect "YiString", "outright", "ReverbSC", "inright"
connect "Bower", "outleft", "ReverbSC", "inleft"
connect "Bower", "outright", "ReverbSC", "inright"
connect "ReverbSC", "outleft", "MasterOutput", "inleft"
connect "ReverbSC", "outright", "MasterOutput", "inright"

alwayson "ReverbSC"
alwayson "MasterOutput"

gk_overlap init .0125

gk_ZakianFlute_level init -4
gk_ZakianFlute_pan init (2 / 7 - .5)
gi_ZakianFLute_seed init .5
gif2 ftgen 0, 0, 16, -2, 40, 40, 80, 160, 320, 640, 1280, 2560, 5120, 10240, 10240
gif26 ftgen 0, 0, 65536, -10, 2000, 489, 74, 219, 125, 9, 33, 5, 5
gif27 ftgen 0, 0, 65536, -10, 2729, 1926, 346, 662, 537, 110, 61, 29, 7
gif28 ftgen 0, 0, 65536, -10, 2558, 2012, 390, 361, 534, 139, 53, 22, 10, 13, 10
gif29 ftgen 0, 0, 65536, -10, 12318, 8844, 1841, 1636, 256, 150, 60, 46, 11
gif30 ftgen 0, 0, 65536, -10, 1229, 16, 34, 57, 32
gif31 ftgen 0, 0, 65536, -10, 163, 31, 1, 50, 31
gif32 ftgen 0, 0, 65536, -10, 4128, 883, 354, 79, 59, 23
gif33 ftgen 0, 0, 65536, -10, 1924, 930, 251, 50, 25, 14
gif34 ftgen 0, 0, 65536, -10, 94, 6, 22, 8
gif35 ftgen 0, 0, 65536, -10, 2661, 87, 33, 18
gif36 ftgen 0, 0, 65536, -10, 174, 12
gif37 ftgen 0, 0, 65536, -10, 314, 13
giwtsin ftgen 0, 0, 65536, 10, 1
instr ZakianFlute
; Author: Lee Zakian
; Adapted by: Michael Gogins
i_instrument = p1
i_time = p2
i_duration = 1000
i_midi_key = p4
i_midi_velocity = p5
k_space_front_to_back = p6
k_space_left_to_right = p1/6
k_space_bottom_to_top = p8
i_phase = p9
i_overall_amps = 65
i_amplitude ampmidicurve i_midi_velocity, gi_ampmidicurve_dynamic_range, gi_ampmidicurve_exponent
k_gain = ampdb(gk_ZakianFlute_level)
iattack = .002
isustain = i_duration
irelease = .3
iHz = cpsmidinn(i_midi_key)
kHz = k(iHz)
aenvelope transeg 1.0, 20.0, -10.0, 0.05
ip3 = (p3 < 3.0 ? p3 : 3.0)
; parameters
; p4 overall amplitude scaling factor
ip4 init i_amplitude
; p5 pitch in Hertz (normal pitch range: C4-C7)
ip5 init iHz
; p6 percent vibrato depth, recommended values in range [-1., +1.]
ip6 init 0.5
; 0.0 -> no vibrato
; +1. -> 1% vibrato depth, where vibrato rate increases slightly
; -1. -> 1% vibrato depth, where vibrato rate decreases slightly
; p7 attack time in seconds
; recommended value: .12 for slurred notes, .06 for tongued notes
; (.03 for short notes)
ip7 init .08
; p8 decay time in seconds
; recommended value: .1 (.05 for short notes)
ip8 init .08
; p9 overall brightness / filter cutoff factor
; 1 -> least bright / minimum filter cutoff frequency (40 Hz)
; 9 -> brightest / maximum filter cutoff frequency (10,240Hz)
ip9 init 5
; initial variables
iampscale = ip4 ; overall amplitude scaling factor
ifreq = ip5 ; pitch in Hertz
ivibdepth = abs(ip6*ifreq/100.0) ; vibrato depth relative to fundamental frequency
iattack = ip7 * (1.1 - .2*gi_ZakianFLute_seed) ; attack time with up to +-10% random deviation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947) ; reset gi_ZakianFLute_seed
idecay = ip8 * (1.1 - .2*gi_ZakianFLute_seed) ; decay time with up to +-10% random deviation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
ifiltcut tablei ip9, gif2 ; lowpass filter cutoff frequency
iattack = (iattack < 6/kr ? 6/kr : iattack) ; minimal attack length
idecay = (idecay < 6/kr ? 6/kr : idecay) ; minimal decay length
isustain = p3 - iattack - idecay
p3 = (isustain < 5/kr ? iattack+idecay+5/kr : p3) ; minimal sustain length
isustain = (isustain < 5/kr ? 5/kr : isustain)
iatt = iattack/6
isus = isustain/4
idec = idecay/6
iphase = gi_ZakianFLute_seed ; use same phase for all wavetables
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
; vibrato block
; kvibdepth linseg .1, .8*p3, 1, .2*p3, .7
kvibdepth linseg .1, .8*ip3, 1, isustain, 1, .2*ip3, .7
kvibdepth = kvibdepth* ivibdepth ; vibrato depth
kvibdepthr randi .1*kvibdepth, 5, gi_ZakianFLute_seed ; up to 10% vibrato depth variation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kvibdepth = kvibdepth + kvibdepthr
ivibr1 = gi_ZakianFLute_seed ; vibrato rate
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
ivibr2 = gi_ZakianFLute_seed
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
if ip6 < 0 goto vibrato1
kvibrate linseg 2.5+ivibr1, p3, 4.5+ivibr2 ; if p6 positive vibrato gets faster
 goto vibrato2
vibrato1:
ivibr3 = gi_ZakianFLute_seed
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kvibrate linseg 3.5+ivibr1, .1, 4.5+ivibr2, p3-.1, 2.5+ivibr3 ; if p6 negative vibrato gets slower
vibrato2:
kvibrater randi .1*kvibrate, 5, gi_ZakianFLute_seed ; up to 10% vibrato rate variation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kvibrate = kvibrate + kvibrater
kvib oscili kvibdepth, kvibrate, giwtsin
ifdev1 = -.03 * gi_ZakianFLute_seed ; frequency deviation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
ifdev2 = .003 * gi_ZakianFLute_seed
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
ifdev3 = -.0015 * gi_ZakianFLute_seed
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
ifdev4 = .012 * gi_ZakianFLute_seed
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kfreqr linseg ifdev1, iattack, ifdev2, isustain, ifdev3, idecay, ifdev4
kfreq = kHz * (1 + kfreqr) + kvib
if ifreq < 427.28 goto range1 ; (cpspch(8.08) + cpspch(8.09))/2
if ifreq < 608.22 goto range2 ; (cpspch(9.02) + cpspch(9.03))/2
if ifreq < 1013.7 goto range3 ; (cpspch(9.11) + cpspch(10.00))/2
goto range4
; wavetable amplitude envelopes
range1: ; for low range tones
kamp1 linseg 0, iatt, 0.002, iatt, 0.045, iatt, 0.146, iatt, \
0.272, iatt, 0.072, iatt, 0.043, isus, 0.230, isus, 0.000, isus, \
0.118, isus, 0.923, idec, 1.191, idec, 0.794, idec, 0.418, idec, \
0.172, idec, 0.053, idec, 0
kamp2 linseg 0, iatt, 0.009, iatt, 0.022, iatt, -0.049, iatt, \
-0.120, iatt, 0.297, iatt, 1.890, isus, 1.543, isus, 0.000, isus, \
0.546, isus, 0.690, idec, -0.318, idec, -0.326, idec, -0.116, idec, \
-0.035, idec, -0.020, idec, 0
kamp3 linseg 0, iatt, 0.005, iatt, -0.026, iatt, 0.023, iatt, \
0.133, iatt, 0.060, iatt, -1.245, isus, -0.760, isus, 1.000, isus, \
0.360, isus, -0.526, idec, 0.165, idec, 0.184, idec, 0.060, idec, \
0.010, idec, 0.013, idec, 0
iwt1 = gif26 ; wavetable numbers
iwt2 = gif27
iwt3 = gif28
inorm = 3949
goto end
range2: ; for low mid-range tones
kamp1 linseg 0, iatt, 0.000, iatt, -0.005, iatt, 0.000, iatt, \
0.030, iatt, 0.198, iatt, 0.664, isus, 1.451, isus, 1.782, isus, \
1.316, isus, 0.817, idec, 0.284, idec, 0.171, idec, 0.082, idec, \
0.037, idec, 0.012, idec, 0
kamp2 linseg 0, iatt, 0.000, iatt, 0.320, iatt, 0.882, iatt, \
1.863, iatt, 4.175, iatt, 4.355, isus, -5.329, isus, -8.303, isus, \
-1.480, isus, -0.472, idec, 1.819, idec, -0.135, idec, -0.082, idec, \
-0.170, idec, -0.065, idec, 0
kamp3 linseg 0, iatt, 1.000, iatt, 0.520, iatt, -0.303, iatt, \
0.059, iatt, -4.103, iatt, -6.784, isus, 7.006, isus, 11, isus, \
12.495, isus, -0.562, idec, -4.946, idec, -0.587, idec, 0.440, idec, \
0.174, idec, -0.027, idec, 0
iwt1 = gif29
iwt2 = gif30
iwt3 = gif31
inorm = 27668.2
goto end
range3: ; for high mid-range tones
kamp1 linseg 0, iatt, 0.005, iatt, 0.000, iatt, -0.082, iatt, \
0.36, iatt, 0.581, iatt, 0.416, isus, 1.073, isus, 0.000, isus, \
0.356, isus, .86, idec, 0.532, idec, 0.162, idec, 0.076, idec, 0.064, \
idec, 0.031, idec, 0
kamp2 linseg 0, iatt, -0.005, iatt, 0.000, iatt, 0.205, iatt, \
-0.284, iatt, -0.208, iatt, 0.326, isus, -0.401, isus, 1.540, isus, \
0.589, isus, -0.486, idec, -0.016, idec, 0.141, idec, 0.105, idec, \
-0.003, idec, -0.023, idec, 0
kamp3 linseg 0, iatt, 0.722, iatt, 1.500, iatt, 3.697, iatt, \
0.080, iatt, -2.327, iatt, -0.684, isus, -2.638, isus, 0.000, isus, \
1.347, isus, 0.485, idec, -0.419, idec, -.700, idec, -0.278, idec, \
0.167, idec, -0.059, idec, 0
iwt1 = gif32
iwt2 = gif33
iwt3 = gif34
inorm = 3775
goto end
range4: ; for high range tones
kamp1 linseg 0, iatt, 0.000, iatt, 0.000, iatt, 0.211, iatt, \
0.526, iatt, 0.989, iatt, 1.216, isus, 1.727, isus, 1.881, isus, \
1.462, isus, 1.28, idec, 0.75, idec, 0.34, idec, 0.154, idec, 0.122, \
idec, 0.028, idec, 0
kamp2 linseg 0, iatt, 0.500, iatt, 0.000, iatt, 0.181, iatt, \
0.859, iatt, -0.205, iatt, -0.430, isus, -0.725, isus, -0.544, isus, \
-0.436, isus, -0.109, idec, -0.03, idec, -0.022, idec, -0.046, idec, \
-0.071, idec, -0.019, idec, 0
kamp3 linseg 0, iatt, 0.000, iatt, 1.000, iatt, 0.426, iatt, \
0.222, iatt, 0.175, iatt, -0.153, isus, 0.355, isus, 0.175, isus, \
0.16, isus, -0.246, idec, -0.045, idec, -0.072, idec, 0.057, idec, \
-0.024, idec, 0.002, idec, 0
iwt1 = gif35
iwt2 = gif36
iwt3 = gif37
inorm = 4909.05
goto end
end:
kampr1 randi .02*kamp1, 10, gi_ZakianFLute_seed ; up to 2% wavetable amplitude variation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kamp1 = kamp1 + kampr1
kampr2 randi .02*kamp2, 10, gi_ZakianFLute_seed ; up to 2% wavetable amplitude variation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kamp2 = kamp2 + kampr2
kampr3 randi .02*kamp3, 10, gi_ZakianFLute_seed ; up to 2% wavetable amplitude variation
gi_ZakianFLute_seed = frac(gi_ZakianFLute_seed*105.947)
kamp3 = kamp3 + kampr3
awt1 poscil kamp1, kfreq, iwt1, iphase ; wavetable lookup
awt2 poscil kamp2, kfreq, iwt2, iphase
awt3 poscil kamp3, kfreq, iwt3, iphase
asig = awt1 + awt2 + awt3
asig = asig*(iampscale/inorm)
kcut linseg 0, iattack, ifiltcut, isustain, ifiltcut, idecay, 0 ; lowpass filter for brightness control
afilt tone asig, kcut
a_signal balance afilt, asig
i_attack = .002
i_sustain = p3
i_release = 0.01
xtratim i_attack + i_sustain + i_release
a_declicking linsegr 0, i_attack, 1, i_sustain, 1, i_release, 0
a_signal = a_signal * i_amplitude * a_declicking * k_gain
#ifdef USE_SPATIALIZATION
a_spatial_reverb_send init 0
a_bsignal[] init 16
a_bsignal, a_spatial_reverb_send Spatialize a_signal, k_space_front_to_back, k_space_left_to_right, k_space_bottom_to_top
outletv "outbformat", a_bsignal
outleta "out", a_spatial_reverb_send
#else
a_out_left, a_out_right pan2 a_signal, p1/6
outleta "outleft", a_out_left
outleta "outright", a_out_right
#endif
prints "ZakianFlute    i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
endin

gk_Guitar_level init 8
instr Guitar
; Michael Gogins
i_instrument = p1
i_time = p2
i_duration = 100
i_midi_key = p4
i_midi_velocity = p5
k_space_front_to_back = p6
k_space_left_to_right = p1/6
k_space_bottom_to_top = p8
i_phase = p9
i_frequency = cpsmidinn(i_midi_key)
i_amplitude ampmidicurve i_midi_velocity, gi_ampmidicurve_dynamic_range, gi_ampmidicurve_exponent
k_gain = ampdb(gk_Guitar_level)
acomp pluck i_amplitude, 440.0, 440.0, 0, 1, .1
i_frequency2 = i_frequency / 2.0
kHz = k(i_frequency)
iattack = 0.004
isustain = p3
irelease = 0.05
p3 = iattack + isustain + irelease
asigcomp pluck 1.0, 440, 440, 0, 1
asig pluck 1.0, i_frequency, i_frequency, 0, 1
af1 reson asig, 110, 80
af2 reson asig, 220, 100
af3 reson asig, 440, 80
aout balance 0.6 * af1 + af2 + 0.6 * af3 + 0.4 * asig, asigcomp
aexp expseg 1.0, iattack, 2.0, isustain, 1.0, irelease, 1.0
aenv = aexp - 1.0
a_signal = aout * aenv
a_declicking linsegr 0, iattack, 1, isustain, 1, irelease, 0
a_signal = a_signal * i_amplitude * a_declicking * k_gain
#ifdef USE_SPATIALIZATION
a_spatial_reverb_send init 0
a_bsignal[] init 16
a_bsignal, a_spatial_reverb_send Spatialize a_signal, k_space_front_to_back, k_space_left_to_right, k_space_bottom_to_top
outletv "outbformat", a_bsignal
outleta "out", a_spatial_reverb_send
#else
a_out_left, a_out_right pan2 a_signal, p1/6
outleta "outleft", a_out_left
outleta "outright", a_out_right
#endif
prints "Guitar         i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
endin

gk_YiString_level init 6
gk_YiString_reverb_send init .5
gk_YiString_chorus_send init .5
gi_YiString_overlap init .1
instr YiString
 //////////////////////////////////////////////
 // Original by Steven Yi.
 // Adapted by Michael Gogins.
 //////////////////////////////////////////////
i_instrument = p1
i_time = p2
i_duration = 1000
i_midi_key = p4
i_midi_velocity = p5
k_space_front_to_back = p6
k_space_left_to_right = p1/6
k_space_bottom_to_top = p8
i_phase = p9
i_frequency = cpsmidinn(i_midi_key)
i_amplitude ampmidicurve i_midi_velocity, gi_ampmidicurve_dynamic_range, gi_ampmidicurve_exponent
k_gain = ampdb(gk_YiString_level)
iattack = gi_YiString_overlap
isustain = i_duration
idecay = gi_YiString_overlap
aenvelope transegr 0.0, iattack / 2.0, 1.5, i_amplitude / 2.0, iattack / 2.0, -1.5, i_amplitude, isustain, 0.0, i_amplitude, idecay / 2.0, 1.5, i_amplitude / 2.0, idecay / 2.0, -1.5, 0
;ampenv = madsr:a(1, 0.1, 0.95, 0.5)
asignal = vco2(1, i_frequency)
asignal = moogladder(asignal, 6000, 0.1)
a_signal = asignal * aenvelope
i_attack = .002
i_release = 0.01
i_sustain = p3 - (i_attack + i_release)
a_declicking linsegr 0, i_attack, 1, i_sustain, 1, i_release, 0
a_signal = a_signal * i_amplitude * a_declicking * k_gain
#ifdef USE_SPATIALIZATION
a_spatial_reverb_send init 0
a_bsignal[] init 16
a_bsignal, a_spatial_reverb_send Spatialize a_signal, k_space_front_to_back, k_space_left_to_right, k_space_bottom_to_top
outletv "outbformat", a_bsignal
outleta "out", a_spatial_reverb_send
#else
a_out_left, a_out_right pan2 a_signal, p1/6
outleta "outleft", a_out_left * gk_YiString_reverb_send
outleta "outright", a_out_right * gk_YiString_reverb_send
outleta "chorusleft", a_out_left * gk_YiString_chorus_send
outleta "chorusright", a_out_right * gk_YiString_chorus_send
;printks "YiString         %9.4f  %9.4f\n", 0.5, a_out_left, a_out_right
#endif
prints  "YiString       i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
endin

gk_Bower_level init 20
gk_Bower_pressure init 4.2
gisine ftgen 0,0,65536,10,1
instr Bower
insno = p1
istart = p2
iduration = 1000
ikey = p4
ivelocity = p5
iphase = p6
ipan = (4 / 7 - .5)
iamp ampmidicurve ivelocity, gi_ampmidicurve_dynamic_range, gi_ampmidicurve_exponent
iattack = i(gk_overlap)
idecay = i(gk_overlap)
isustain = iduration
kenvelope transegr 0.0, iattack / 2.0, 1.5, iamp / 2.0, iattack / 2.0, -1.5, iamp, isustain, 0.0, iamp, idecay / 2.0, 1.5, iamp / 2.0, idecay / 2.0, -1.5, 0
ihertz = cpsmidinn(ikey)
kamp = kenvelope
kfreq = ihertz
kpres = 0.25
krat rspline 0.006,0.988,1,2
kvibf = 4.5
kvibamp = 0
iminfreq = 30
aSig wgbow kamp,kfreq,gk_Bower_pressure,krat,kvibf,kvibamp,gisine,iminfreq
aleft, aright pan2 aSig / 7, p1/6
adamping linseg 0, 0.03, 1, p3 - 0.1, 1, 0.07, 0
aleft = adamping * aleft
aright = adamping * aright
kgain = ampdb(gk_Bower_level)
outleta "outleft", aleft * kgain
outleta "outright", aright * kgain
prints "Bower          i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
endin

gk_Harpsichord_level init 0
gk_Harpsichord_pick init .275
gk_Harpsichord_reflection init .75
gk_Harpsichord_pluck init .5
giharptable ftgen 0, 0, 65536, 7, -1, 1024, 1, 1024, -1
instr Harpsichord
i_instrument = p1
i_time = p2
i_duration = p3
i_midi_key = p4
i_midi_velocity = p5
k_space_front_to_back = p6
k_space_left_to_right = .2
k_space_bottom_to_top = p8
i_phase = p9
i_amplitude ampmidicurve i_midi_velocity, gi_ampmidicurve_dynamic_range, gi_ampmidicurve_exponent
k_gain = ampdb(gk_Harpsichord_level)
iHz = cpsmidinn(i_midi_key)
kHz = k(iHz)
aenvelope transeg 1.0, 20.0, -10.0, 0.05
k_amplitude = 1
apluck pluck 1, kHz, iHz, 0, 1
aharp poscil 1, kHz, giharptable
aharp2 balance apluck, aharp
a_signal	= (apluck + aharp2)
i_attack = .002
i_sustain = i_duration
i_release = 0.01
a_declicking linsegr 0, i_attack, 1, i_sustain, 1, i_release, 0
a_signal = a_signal * i_amplitude * a_declicking * k_gain
#ifdef USE_SPATIALIZATION
a_spatial_reverb_send init 0
a_bsignal[] init 16
a_bsignal, a_spatial_reverb_send Spatialize a_signal, k_space_front_to_back, k_space_left_to_right, k_space_bottom_to_top
outletv "outbformat", a_bsignal
outleta "out", a_spatial_reverb_send
#else
a_out_left, a_out_right pan2 a_signal, p1/6
outleta "outleft", a_out_left
outleta "outright", a_out_right
#endif
; printks "Harpsichord      %9.4f   %9.4f\n", 0.5, a_out_left, a_out_right
prints "Harpsichord    i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
kpbend    pchbend   2
printks2 "pchbend %9.4f\n", kpbend
kmodw     midictrl  1
printks2 "kmodw   %9.4f\n", kmodw
kctl6     midictrl  6
printks2 "kctl6   %9.4f\n", kctl6
kctl4     midictrl  4
printks2 "kctl4   %9.4f\n", kctl4
kctl5     midictrl  5
printks2 "kctl5   %9.4f\n", kctl5
kafter    aftouch   1
printks2 "kafter  %9.4f\n", kafter

endin

gk_Reverb_feedback init 0.85
gi_Reverb_delay_modulation init 0.05
gk_Reverb_frequency_cutoff init 15000
instr ReverbSC
aleftout init 0
arightout init 0
aleft inleta "inleft"
aright inleta "inright"
; aoutL, aoutR reverbsc ainL, ainR, kfblvl, kfco[, israte[, ipitchm[, iskip]]]
aleftout, arightout reverbsc aleft, aright, gk_Reverb_feedback, gk_Reverb_frequency_cutoff, sr, gi_Reverb_delay_modulation
outleta "outleft", aleftout
outleta "outright", arightout
prints "ReverbSC       i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\\n", p1, p2, p3, p4, p5, p1/6, active(p1)
endin

gk_MasterOutput_level init -15
gS_MasterOutput_filename init ""
instr MasterOutput
aleft inleta "inleft"
aright inleta "inright"
k_gain = ampdb(gk_MasterOutput_level)
printks2 "Master gain: %f\n", k_gain
iamp init 1
iattack init .01
idecay init 10
isustain = 2400 - (iattack + idecay)
aenvelope transeg 0.0, iattack / 2.0, 1.5, iamp / 2.0, iattack / 2.0, -1.5, iamp, isustain, 0.0, iamp, idecay / 2.0, 1.5, iamp / 2.0, idecay / 2.0, -1.5, 0
aleft butterlp aleft, 18000
aright butterlp aright, 18000
outs aleft * k_gain * aenvelope, aright * k_gain * aenvelope
; We want something that will play on my phone.
i_amplitude_adjustment = ampdbfs(-3) / 32767
i_filename_length strlen gS_MasterOutput_filename
if i_filename_length > 0 goto has_filename
goto non_has_filename
has_filename:
prints sprintf("Output filename: %s\n", gS_MasterOutput_filename)
fout gS_MasterOutput_filename, 18, aleft * i_amplitude_adjustment, aright * i_amplitude_adjustment
non_has_filename:
prints "MasterOutput   i %9.4f t %9.4f d %9.4f k %9.4f v %9.4f p %9.4f #%3d\n", p1, p2, p3, p4, p5, p1/6, active(p1)
kstatus, kchan, kdata1, kdata2 midiin
;printf "          midi in s %4d c %4d %4d %4d\n", kdata2, kstatus, kchan, kdata1, kdata2
endin

</CsInstruments>
<CsScore>
</CsScore>
</CsoundSynthesizer>    
    </textarea>

    <script id="draw-shader-fs" type="x-shader/x-fragment">#version 300 es
        #line 614
        precision mediump float;
        /**
         * These are all of the standard ShaderToy inputs. If any of these are 
         * used in this shader, they must be created and initialized in the 
         * JavaScript code.
         */
        uniform vec3 iResolution;
        // viewport resolution (in pixels)
        uniform float iTime;
        // shader playback time (in seconds)
        uniform float iTimeDelta;
        // render time (in seconds)
        uniform int iFrame;
        // shader playback frame
        uniform float iChannelTime[4];
        // channel playback time (in seconds)
        uniform vec3 iChannelResolution[4];
        // channel resolution (in pixels)
        uniform vec4 iMouse;
        // mouse pixel coords. xy: current (if MLB down), zw: click
        uniform sampler2D iChannel0;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel1;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel2;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel3;
        // input channel. XX = 2D/Cube
        uniform vec4 iDate;
        // (year, month, day, time in seconds)
        uniform float iSampleRate;
        // sound sample rate (i.e., 44100)
        
        /**
         * Theoretically, any fragment shader copied from the ShaderToy 
         * editor can replace the body of the mainImage function below, 
         * if all inputs actually used in the shader are defined and bound.
         */

        void mainImage(out vec4 _ufragColor, in vec2 _ufragCoord);
        out vec4 _ushadertoy_out_color;
        void main(){
          (_ushadertoy_out_color = vec4(0.0, 0.0, 0.0, 0.0));
          (_ushadertoy_out_color = vec4(1.0, 1.0, 1.0, 1.0));
          vec4 _ucolor = vec4(0.0, 0.0, 0.0, 1.0);
          mainImage(_ucolor, gl_FragCoord.xy);
          if ((_ushadertoy_out_color.x < 0.0))
          {
            (_ucolor = vec4(1.0, 0.0, 0.0, 1.0));
          }
          if ((_ushadertoy_out_color.y < 0.0))
          {
            (_ucolor = vec4(0.0, 1.0, 0.0, 1.0));
          }
          if ((_ushadertoy_out_color.z < 0.0))
          {
            (_ucolor = vec4(0.0, 0.0, 1.0, 1.0));
          }
          if ((_ushadertoy_out_color.w < 0.0))
          {
            (_ucolor = vec4(1.0, 1.0, 0.0, 1.0));
          }
          (_ushadertoy_out_color = vec4(_ucolor.xyz, 1.0));
        }
        float hash(int x) { return fract(sin(float(x))*7.847); } 

        float dSegment(vec2 a, vec2 b, vec2 c)
        {
            vec2 ab = b-a;
            vec2 ac = c-a;
            float h = clamp(dot(ab, ac)/dot(ab, ab), 0., 1.);
            vec2 point = a+ab*h;
            return length(c-point);
        }

vec2 triangle_wave(vec2 a){
    return abs(fract((a+vec2(1.,0.5))*1.5)-.5);
}

void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    fragColor = vec4(0.0);
    vec3 col = vec3(0.);
    float t1 = 8.*8.;
    vec2 uv = (fragCoord)/iResolution.y/t1/2.0;
    uv.y += iTime/t1/12.0;
    float scale = 1.5;
    vec2 t2 = vec2(0.);
    vec3 col1 = col;

    for(int k = 0; k < 12; k++){
        bool c1 = t2.x < uv.x;
        uv = (uv+t2)/scale;
        t2 = triangle_wave(uv-.5);
        uv = t2-triangle_wave(uv.yx);
        float z1 =
            //Several interesting variants here:
            abs(uv.x-uv.y)-t2.x-t2.y;
            //length(uv-t2);
            //max(abs(t2.y),abs(uv.y));
            //max(abs(t2.x),abs(uv.x));
            //abs(uv.y)-t2.y;
            //abs(uv.x)-t2.x;
            //max(abs(uv.x-t2.x),abs(uv.y-t2.y));
            //uv.x-t2.x;
            //t2.y;
            //abs(uv.x+uv.y)-t2.x-t2.y;
            //t2.x+uv.x;
            //uv.x+t2.x;
            
            //max(abs(t2.y-uv.y),abs(t2.x-uv.x));

            //max(abs(uv.y),abs(uv.x));

        col.x = max((abs(z1))/3.,col.x);
        col =
            abs(col-(1.-col.x));
            //abs(col.yzx-(1.-col.x));
        col1 =
            abs(col1-col-1.).yzx;
            //col1 = abs(abs(col1-1.)-col).yzx;

        
        //if(c1) col =
            //col.yzx;
            //abs(col.yzx-col);
    }
    fragColor = vec4(col1/2.,1.0);
}
              
    </script>

    <script id="draw-shader-vs" type="x-shader/x-vertex">#version 300 es
        in vec2 inPos;
        void main() {
            gl_Position = vec4(inPos.xy, 0.0, 1.0);
        }
    </script>
    
    <script> 
        /**
         * Encapsulates the combination of Csound with a GLSL fragment shader 
         * as a music visualizer or score generator. Csound may pass audio 
         * data in both the time domain and the frequency domain to the shader 
         * for visualization, and the canvas may be sampled to generate Csound 
         * events and pass them to Csound for rendering by Csound instruments.
         *
         * Many fragment shaders from Shadertoy.com will run more or less out 
         * of the box in this code. Other shaders may of course also be used 
         * or written.
         */
        class ShaderAdapter {
            constructor(csound, canvas) {
                this.csound = csound;
                this.canvas = canvas;
                
            };
        };
        
        var shader_program = null;
        var analyser = null;
        // Set up for high-resolution displays.
        var devicePixelRatio_ = window.devicePixelRatio || 1
        var canvas = document.getElementById( "display");
        canvas.width = canvas.clientWidth * devicePixelRatio_;
        canvas.height = canvas.clientHeight * devicePixelRatio_;
        console.log("canvas.height: " + canvas.height);
        console.log("canvas.width:  " + canvas.width);
        var gl = canvas.getContext("webgl2", { antialias: true });
        if (!gl) {
            alert("Could not create webgl2 context.");
        }
        let extensions = gl.getSupportedExtensions();
        console.log("Supported extensions:\n" + extensions);
        if ("gpu" in navigator) {
            var gpu_adapter = navigator.gpu.requestAdapter();
            console.log("WebGPU adapter: " + gpu_adapter);
        } else {
            console.warn("WebGPU is not available on this platform.");
        }
        var EXT_color_buffer_float = gl.getExtension("EXT_color_buffer_float");
        if (!EXT_color_buffer_float) {
            alert("EXT_color_buffer_float is not available on this platform.");
        }
        var WEBGL_debug_shaders = gl.getExtension("WEBGL_debug_shaders");
        const audio_texture_level = 0;
        const audio_texture_internalFormat = gl.R32F;
        const audio_texture_width = 512;
        const audio_texture_height = 2;
        const audio_texture_border = 0;
        const audio_texture_srcFormat = gl.RED;
        const audio_texture_srcType = gl.FLOAT;
        var frequency_domain_data = new Uint8Array(audio_texture_width * 2);
        var time_domain_data = new Uint8Array(audio_texture_width * 2);
        var audio_data = new Float32Array(audio_texture_width * 2);
        var image_sample_buffer = new Uint8ClampedArray();
        
        var channel0_texture_unit = 0;
        var channel0_texture = gl.createTexture();
        channel0_texture.name = "channel0_texture";
        var channel0_sampler = gl.createSampler();
        channel0_sampler.name - "channel0_sampler";
 
        var current_events = new Map();
        var prior_events = current_events;
        var rendering_iterations_per_sample = 5;
        var rendering_frame = 0;
        
        function write_audio_texture(analyser, texture_unit, texture, sampler) {
           if (analyser != null) {
                analyser.getByteFrequencyData(frequency_domain_data);
                analyser.getByteTimeDomainData(time_domain_data);
                for (let i = 0; i < audio_texture_width; ++i) {
                    // Map frequency domain magnitudes to [0, 1].
                    let sample = frequency_domain_data[i];
                    sample = sample / 255.;
                    audio_data[i] = sample;
                 }
                let audio_data_width = audio_texture_width * 2;
                for (let j = 0; j < audio_texture_width; ++j) {
                    // Map time domain amplitudes to [-1, 1].
                    let sample = time_domain_data[j];
                    sample = sample / 255.;
                    audio_data[audio_texture_width + j] = sample;
                }
            }
            gl.activeTexture(gl.TEXTURE0 + texture_unit);
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.bindSampler(texture_unit, sampler);
            gl.texImage2D(gl.TEXTURE_2D, audio_texture_level, audio_texture_internalFormat, audio_texture_width, audio_texture_height, audio_texture_border, audio_texture_srcFormat,audio_texture_srcType, audio_data);
            gl.samplerParameteri(sampler, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.samplerParameteri(sampler, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_WRAP_R, gl.CLAMP_TO_EDGE);
            gl.samplerParameteri(sampler, gl.TEXTURE_COMPARE_MODE, gl.NONE);
            gl.samplerParameteri(sampler, gl.TEXTURE_COMPARE_FUNC, gl.LEQUAL);
            if (false && analyser) { // For debugging.
                let is_texture = gl.isTexture(texture);
                let uniform_count = gl.getProgramParameter(shader_program, gl.ACTIVE_UNIFORMS);
                let uniform_index;
                for (let uniform_index = 0; uniform_index < uniform_count; ++uniform_index) {
                    uniform_info = gl.getActiveUniform(shader_program, uniform_index);
                    console.log(uniform_info);
                    const location = gl.getUniformLocation(shader_program, uniform_info.name);
                    const value = gl.getUniform(shader_program, location);
                    console.log("Uniform location: " + location);
                    console.log("Uniform value: " + value);
                }
                const unit = gl.getUniform(shader_program, shader_program.iChannel0);
                console.log("Sampler texture unit: " + unit);
                console.log("Texture unit: " + texture_unit);
                gl.activeTexture(gl.TEXTURE0 + texture_unit);
                let texture2D = gl.getParameter(gl.TEXTURE_BINDING_2D);
                console.log("Texture binding 2D " + texture2D);
                var debug_framebuffer = gl.createFramebuffer();
                gl.bindFramebuffer(gl.FRAMEBUFFER, debug_framebuffer);
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture2D, 0);
                if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
                    console.log("These attachments don't work.");
                }
                // Read the contents of the debug_framebuffer (data stores the pixel data).
                var data = new Float32Array(1024);
                // What comes out, should be what went in.
                gl.readPixels(0, 0, 512, 2, gl.RED, gl.FLOAT, data);
                //console.log("\nfrequency domain: \n" + data.slice(0, 512));
                //console.log("time domain: \n" + data.slice(512));
                gl.deleteFramebuffer(debug_framebuffer);
            }
         }
        
        (function load_scene() {
            var webgl_viewport_size;
            var webgl_buffers = {};
            var mouse_position = [0, 0, 0, 0];
            function create_scene() {
                console.log("VENDOR: " + gl.getParameter(gl.VENDOR));
                console.log("RENDERER: " + gl.getParameter(gl.RENDERER));
                console.log("GL_VERSION: " + gl.getParameter(gl.VERSION));
                console.log("SHADING_LANGUAGE_VERSION: " + gl.getParameter(gl.SHADING_LANGUAGE_VERSION));
                canvas.addEventListener('mousemove', (e) => {
                    mouse_position = [e.clientX, e.clientY];
                });
                shader_program = gl.createProgram();
                for (let i = 0; i < 2; ++i) {
                    let shader_code = document.getElementById(i==0 ? "draw-shader-vs" : "draw-shader-fs").text;
                    let shader_object = gl.createShader(i==0 ? gl.VERTEX_SHADER : gl.FRAGMENT_SHADER);
                    gl.shaderSource(shader_object, shader_code);
                    gl.compileShader(shader_object);
                    let status = gl.getShaderParameter(shader_object, gl.COMPILE_STATUS);
                    if (!status) {
                        console.warn(gl.getShaderInfoLog(shader_object));
                    }
                    gl.attachShader(shader_program, shader_object);
                    gl.linkProgram(shader_program);
                    console.log("shader:" + WEBGL_debug_shaders.getTranslatedShaderSource(shader_object));
                }
                status = gl.getProgramParameter(shader_program, gl.LINK_STATUS);
                if (!status) {
                    console.warn(gl.getProgramInfoLog(shader_program));
                }
                shader_program.inPos = gl.getAttribLocation(shader_program, "inPos");
                shader_program.iMouse = gl.getUniformLocation(shader_program, "iMouse");
                shader_program.iResolution = gl.getUniformLocation(shader_program, "iResolution");
                shader_program.iTime = gl.getUniformLocation(shader_program, "iTime");
                shader_program.iTimeDelta = gl.getUniformLocation(shader_program, "iTimeDelta");
                shader_program.iFrame = gl.getUniformLocation(shader_program, "iFrame");
                shader_program.iChannel0 = gl.getUniformLocation(shader_program, "iChannel0");
                shader_program.iChannel1 = gl.getUniformLocation(shader_program, "iChannel1");
                shader_program.iChannel2 = gl.getUniformLocation(shader_program, "iChannel2");
                shader_program.iChannel3 = gl.getUniformLocation(shader_program, "iChannel3");
                shader_program.iSampleRate = gl.getUniformLocation(shader_program, "iSampleRate");
                gl.useProgram(shader_program);
               
                gl.uniform1f(shader_program.iSampleRate, 48000.);
                var pos = [ -1, -1, 
                             1, -1, 
                             1,  1, 
                            -1,  1 ];
                var inx = [ 0, 1, 2, 0, 2, 3 ];
                webgl_buffers.pos = gl.createBuffer();
                gl.bindBuffer( gl.ARRAY_BUFFER, webgl_buffers.pos );
                gl.bufferData( gl.ARRAY_BUFFER, new Float32Array( pos ), gl.STATIC_DRAW);
                webgl_buffers.inx = gl.createBuffer();
                webgl_buffers.inx.len = inx.length;
                gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, webgl_buffers.inx );
                gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array( inx ), gl.STATIC_DRAW);
                gl.enableVertexAttribArray(shader_program.inPos);
                gl.vertexAttribPointer(shader_program.inPos, 2, gl.FLOAT, false, 0, 0); 
                gl.enable(gl.DEPTH_TEST);
                gl.clearColor(0.0, 0.0, 0.0, 1.0);
                write_audio_texture(analyser, channel0_texture_unit, channel0_texture, channel0_sampler);
                window.onresize = resize;
                resize();
                requestAnimationFrame(render_scene);
            }

            function resize() {
                webgl_viewport_size = [window.innerWidth, window.innerHeight];
                canvas.width = webgl_viewport_size[0] * window.devicePixelRatio;
                canvas.height = webgl_viewport_size[1] * window.devicePixelRatio;
                image_sample_buffer = new Uint8ClampedArray(canvas.width * 4);
                prior_image_sample_buffer = new Uint8ClampedArray(canvas.width * 4);
                console.info("resize: image_sample_buffer.length: " + image_sample_buffer.length);
            }
            
            function clientWaitAsync(sync, flags, interval_ms) {
                return new Promise((resolve, reject) => {
                    function test() {
                        const result = gl.clientWaitSync(sync, flags, 0);
                        if (result === gl.WAIT_FAILED) {
                            reject();
                            return;
                        }
                        // This is the workaround for platforms where maximum 
                        // timeout is always 0.
                        if (result === gl.TIMEOUT_EXPIRED) {
                            setTimeout(test, interval_ms);
                            return;
                        }
                        resolve();
                    }
                    test();
                });
            }

            async function getBufferSubDataAsync(target, buffer, srcByteOffset, dstBuffer,
                /* optional */ dstOffset, /* optional */ length) {
                const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
                gl.flush();
                await clientWaitAsync(sync, 0, 10);
                gl.deleteSync(sync);
                gl.bindBuffer(target, buffer);
                gl.getBufferSubData(target, srcByteOffset, dstBuffer, dstOffset, length);
                gl.bindBuffer(target, null);
             }
            
            /**
             * Converts an RGB color value to HSV. Conversion formula
             * adapted from http://en.wikipedia.org/wiki/HSV_color_space.
             * Assumes r, g, and b are in [0, 255] and
             * returns h, s, and v in [0, 1].
             */
            var rgb_to_hsv = function(rgb){
                r = rgb[0] / 255;
                g = rgb[1] / 255;
                b = rgb[2] / 255;
                var max = Math.max(r, g, b);
                var min = Math.min(r, g, b);
                var h, s, v = max;
                var d = max - min;
                s = max === 0 ? 0 : d / max;
                if (max == min){
                    h = 0;
                } else {
                    // More efficient than switch?
                    if        (max == r) {
                        h = (g - b) / d + (g < b ? 6 : 0);
                    } else if (max == g) {
                        h = (b - r) / d + 2;
                    } else if (max == b) {
                        h = (r - g) / d + 4;
                    }
                    h /= 6;
                }
                return [h, s, v];
            }

            async function readPixelsAsync(x, y, w, h, format, type, sample) {
                const buffer = gl.createBuffer();
                gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buffer);
                gl.bufferData(gl.PIXEL_PACK_BUFFER, sample.byteLength, gl.STREAM_READ);
                gl.readPixels(x, y, w, h, format, type, 0);
                gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
                await getBufferSubDataAsync(gl.PIXEL_PACK_BUFFER, buffer, 0, sample);
                gl.deleteBuffer(buffer);
            }   
            
            /**
             * Adapts https://github.com/pingec/downsample-lttb from time 
             * series data to vectors of float HSV pixels. Our data is not 
             * [[time, value], [time, value],...]; rather, our data is 
             * [[pixel index0, hsv0[2]], [pixel index1, hsv1[2]], ...].
             */
            // TODO: Change the data layout from [h, s, v] to [i, v, [h, s, v]]
            function downsample_lttb(data, buckets) {
                if (buckets >= data.length || buckets === 0) {
                    return data; // Nothing to do
                }
                let sampled_data = [],
                    sampled_data_index = 0;
                // Bucket size. Leave room for start and end data points
                let bucket_size = (data.length - 2) / (buckets - 2);
                // Triangles are points {a, b, c}.
                let a = 0,  // Initially a is the first point in the triangle
                    max_area_point,
                    max_area,
                    area,
                    next_a;
                sampled_data[sampled_data_index++] = data[a]; // Always add the first point
                for (let i = 0; i < buckets - 2; i++) {
                    // Calculate point average for next bucket (containing c)
                    let avg_x = 0,
                        avg_y = 0,
                        avg_range_start  = Math.floor( ( i + 1 ) * bucket_size ) + 1,
                        avg_range_end    = Math.floor( ( i + 2 ) * bucket_size ) + 1;
                    avg_range_end = avg_range_end < data.length ? avg_range_end : data.length;
                    let avg_range_length = avg_range_end - avg_range_start;
                    for ( ; avg_range_start<avg_range_end; avg_range_start++ ) {
                      avg_x += data[ avg_range_start ][ 0 ] * 1; // * 1 enforces Number (value may be Date)
                      avg_y += data[ avg_range_start ][ 1 ] * 1;
                    }
                    avg_x /= avg_range_length;
                    avg_y /= avg_range_length;
                    // Get the range for this bucket
                    let range_offs = Math.floor( (i + 0) * bucket_size ) + 1,
                        range_to   = Math.floor( (i + 1) * bucket_size ) + 1;
                    // Point a
                    let point_a_x = data[ a ][ 0 ] * 1, // enforce Number (value may be Date)
                        point_a_y = data[ a ][ 1 ] * 1;
                    max_area = area = -1;
                    for ( ; range_offs < range_to; range_offs++ ) {
                        // Calculate triangle area over three buckets
                        area = Math.abs( ( point_a_x - avg_x ) * ( data[ range_offs ][ 1 ] - point_a_y ) -
                                    ( point_a_x - data[ range_offs ][ 0 ] ) * ( avg_y - point_a_y )
                                  ) * 0.5;
                        if ( area > max_area ) {
                            max_area = area;
                            max_area_point = data[ range_offs ];
                            next_a = range_offs; // Next a is this b
                        }
                    }
                    sampled_data[sampled_data_index++] = max_area_point; // Pick this point from the bucket
                    a = next_a; // This a is the next a (chosen b)
                }
                sampled_data[sampled_data_index++] = data[data.length - 1]; // Always add last
                return sampled_data; ///sampled_data;
            }
            
            /**
             * Translates one row of RGBA pixels, the width of the WebGL 
             * canvas, to Csound events. 
             *
             * https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf
             */
            var sampled_events = new Array();
            var on_events = new Array();
            var playing_events = new Map();
            var off_events = new Array();
            var frame_translation_rate = 1;
            var frame_translation_count = 0;
            var midi_key_begin = 36;
            var midi_key_range = 60;
            var instrument_count = 4;
            var maximum_voices = 10;
            var event_velocity_threshold = 100;
            var midi_key_end = midi_key_begin + midi_key_range;
            async function translate_sample_to_csound_events(maximum_events, threshold, parent_rendering_frame) {
                if (csound == null) {
                    return;
                }
                if (!csound.is_playing) {
                    return;
                }
                // Sample the middle row of the canvas.
                let x = 0;
                let y = canvas.height - 1;
                let width = canvas.width;
                let height = 1;
                let format = gl.RGBA;
                let type = gl.UNSIGNED_BYTE;
                readPixelsAsync(x, y, width, height, format, type, image_sample_buffer);
                // Translate the sample format from byte RGBA to float HSV.
                let hsv_image_sample = [];
                for (let byte_i = 0; byte_i < image_sample_buffer.length; byte_i = byte_i + 4) {
                    let rgb = image_sample_buffer.slice(byte_i, byte_i + 3);
                    let hsv = rgb_to_hsv(rgb);
                    hsv_image_sample.push([hsv_image_sample.length + 1, hsv[2], hsv]);
                }
                // Downsample the HSV samples.
                let downsampled_pixels = downsample_lttb(hsv_image_sample, midi_key_range);
                sampled_events.length = 0;
                on_events.length = 0;
                off_events.length = 0;
                // Translate the HSV samples to Csound event vectors.
                for (let downsampled_pixel_i = 0; downsampled_pixel_i < downsampled_pixels.length; downsampled_pixel_i++) {
                    let hsv = downsampled_pixels[downsampled_pixel_i][2];
                    let instrument_number = 1 + (hsv[0] * instrument_count) ;
                    let time = 0;
                    let duration = -1;
                    let midi_key = Math.floor(midi_key_begin + downsampled_pixel_i);
                    let midi_velocity = hsv[2] * 128;
                    let event_for_pixel = [instrument_number, time, duration, midi_key, midi_velocity];
                    sampled_events.push(event_for_pixel);
                }
                for (let sampled_event_i = 0; sampled_event_i < sampled_events.length; sampled_event_i++) {
                    let sampled_event = sampled_events[sampled_event_i];
                    let key = Math.floor(sampled_event[3]);
                    // Events that are loud enough but not playing, are turned on.
                    if ((sampled_event[4] >= event_velocity_threshold) && (playing_events.has(key) == false)) {
                        playing_events.set(key, sampled_event);
                        on_events.push(sampled_event);
                    }
                    // Events that are playing but not loud enough, are turned off.
                    if ((sampled_event[4] < event_velocity_threshold) && (playing_events.has(key) == true)) {
                        let off_event = playing_events.get(key);
                        playing_events.delete(key);
                        off_events.push(off_event);
                    }
                }
                let csound_score = [];
                // 0 is p1 insno, tagged by MIDI key.
                // 1 is p2 time always 0
                // 2 is p3 duration either -1 or 0
                // 3 is p4 MIDI key 
                // 4 is p5 MIDI velocity
                for (let i = 0; i < off_events.length; i++) {
                    let off_event = off_events[i];
                    let instrument_number = Math.floor(off_event[0]);
                    // The 'd' opcode seems to assume a whole insno, so we use 
                    // the 'i' opcode with a negative insno.
                    let i_statement = sprintf("i %d.%d %9.4f %9.4f %9.4f %9.4f\n", -instrument_number, off_event[3], off_event[1], 0, off_event[3], off_event[4]);
                    csound_score.push(i_statement);
                }
                for (let i = 0; i < on_events.length; i++) {
                    let on_event = on_events[i];
                    let instrument_number = Math.floor(on_event[0]);
                    let i_statement = sprintf("i %d.%d %9.4f %9.4f %9.4f %9.4f\n", instrument_number, on_event[3], on_event[1], on_event[2], on_event[3], on_event[4]);
                    csound_score.push(i_statement);
                }
                if (csound_score.length > 0) {
                    let score_text = csound_score.join("");
                    console.log(score_text);
                    csound.ReadScore(score_text);
                }
            }

            /** 
             * As the last step in rendering the scene, this function reads 
             * one row of the canvas (the sample) into an array of pixels, 
             * then translates that row into a set of Csound events, the 
             * mapping determined by a separate function. An attempt is made 
             * to avoid stalling the WebGL rendering pipeline by reading the 
             * pixels from the canvas only when a memory fence around 
             * the GPU pipeline becomes passable.
             */
            async function sample_canvas(current_rendering_frame) {
                //console.info("frame_sample_to_score.");
                await translate_sample_to_csound_events(16, event_velocity_threshold, current_rendering_frame);
            }
            
            function render_scene(delta_milliseconds) {
                rendering_frame++;
                console.info(`render_scene:                      time: ${performance.now() / 1000} frame: ${rendering_frame}`);
                gl.viewport(0, 0, canvas.width, canvas.height);
                gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
                gl.uniform1f(shader_program.iTime, delta_milliseconds / 1000.0);
                gl.uniform3f(shader_program.iResolution, canvas.width, canvas.height, 0);
                gl.uniform4f(shader_program.iMouse, mouse_position[0], mouse_position[1], 0, 0);
                //write_audio_texture(analyser, channel0_texture_unit, channel0_texture, channel0_sampler);
                gl.drawElements(gl.TRIANGLES, webgl_buffers.inx.len, gl.UNSIGNED_SHORT, 0);    
                sample_canvas(rendering_frame);
                requestAnimationFrame(render_scene);
            }  
            create_scene();
        })();    
    
    </script>
    <script>
        var message_callback_buffer = "";
        var csound_message_callback = function(message) {
            // Split in case the newline is in the middle of the message but 
            // not at the end?
            message_callback_buffer = message_callback_buffer + message;
            if (message_callback_buffer.endsWith("\n")) {
                console.log(message_callback_buffer);
                message_callback_buffer = "";
            }
        };
        var CsoundAC;
        var csound = null;
        (async function() { 
            CsoundAC = await createCsoundAC(); 
            //CsoundAC.CHORD_SPACE_DEBUGGING(false);
            var txt = "Browser CodeName: " + navigator.appCodeName + "\n";
            txt += "Browser Name: " + navigator.appName + "\n";
            txt += "Browser Version: " + navigator.appVersion + "\n";
            txt += "Cookies Enabled: " + navigator.cookieEnabled + "\n";
            txt += "Browser Language: " + navigator.language + "\n";
            txt += "Browser Online: " + navigator.onLine + "\n";
            txt += "Platform: " + navigator.platform + "\n";
            txt += "User-agent header: " + navigator.userAgent + "\n";
            csound_message_callback(txt);
            csound_message_callback(CsoundAC.chord_space_version() + "\n");
            let CM = CsoundAC.chordForName("C+");
            CM = CM.T(-4.);
            csound_message_callback(CM.information());
            csound_message_callback(CM.information_debug(-1));
        }());
            
        window.onload = function() {
            $("#about_view").css("display", "none");         
            $("#menu_item_play").click(async function(event) {
                console.log("menu_item_play click...");     
                if (csound == null) {
                    try {
                        csound_message_callback("Trying to load CsoundAudioNode...\n");
                        var AudioContext = window.AudioContext || window.webkitAudioContext;
                        var audioContext = new AudioContext();
                        await audioContext.audioWorklet.addModule('CsoundAudioProcessor.js').then(function() {
                            csound_message_callback("Creating CsoundAudioNode...\n");
                            csound_audio_node = new CsoundAudioNode(audioContext, csound_message_callback);
                            csound_message_callback("CsoundAudioNode (AudioWorklet) is available in this JavaScript context.\n");
                            csound = csound_audio_node;
                            console.log("csound: " + csound);
                        }, function(error) {
                           csound_message_callback(error + '\n');
                        });
                    } catch (e) {
                        csound_message_callback(e + '\n');
                    }
                }
                if (csound.is_playing == false) {
                    let csd = await document.getElementById('csd').value;
                    let result = await csound.CompileCsdText(csd);
                    csound_message_callback("CompileCsdText returned: " + result);
                    await csound.Start();
                    await csound.Perform();
                    analyser = new AnalyserNode(audioContext);
                    analyser.fftSize = 2048;
                    console.log("Analyzer buffer size: " + analyser.frequencyBinCount);
                    csound.connect(analyser);
                    //analyser.connect(audioContext.destination);
                    csound_message_callback("Csound is playing...\n");
                } else {
                    await csound.Stop();
                    await csound.Cleanup();
                    csound.Reset();
                    csound_message_callback("Csound is stopping...\n");
                }
             });
            $("#menu_item_fullscreen").click(function(event) {
                console.log("menu_item_fullscreen click...");
                const display = document.getElementById("display");
                if (display.requestFullscreen) {
                    display.requestFullscreen();
                } else if (display.webkitRequestFullscreen) { 
                    display.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) { 
                    display.msRequestFullscreen();
                }
            });
            $("#menu_item_settings").click(function(event) {
                console.log("menu_item_settings click...");
            });
            $("#menu_item_code").click(function(event) {
                console.log("menu_item_code click...");
             });
            $("#menu_item_notifications").click(function(event) {
                console.log("menu_item_notifications click...");
            });
            $("#menu_item_about").click(function(event) {
                console.log("menu_item_about click...");
                $("#about_view").toggle();            
            });
            $(document).keydown(function(event) {
                console.log("document keydown...");
                if (event.keyCode === 'F11') {
                    $("#menu_item_fullscreen").trigger("click");
                }
            });
        };
    </script>
 </html>
