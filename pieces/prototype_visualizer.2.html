<!DOCTYPE html>
<html>
<head>
<title>Cloud Music No. 1</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script src="https://cdnjs.cloudflare.com/ajax/libs/dat-gui/0.7.1/dat.gui.js"></script>
<script src="https://code.jquery.com/jquery-3.6.0.js" integrity="sha256-H+K7U5CnXl1h5ywQfKtSj8PCmoN9aaq30gDh27Xc0jk=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.1/p5.js" integrity="sha512-4P0ZJ49OMXe3jXT+EsEaq82eNwFeyYL81LeHGzGcEhowFbTqeQ80q+NEkgsE8tHPs6aCqvi7U+XWliAjDmT5Lg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/sprintf/1.1.2/sprintf.js" integrity="sha512-dY9NsJoe4eisOR4ZtU0WaFNOxGcGZMfaviwSYHoiiEXvC6QLBsOOVsv3uY+5lEvuRtGTATg7usKQGajlDWSo7Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/91/three.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/ace/1.9.6/ace.js" integrity="sha512-czfWedq9cnMibaqVP2Sw5Aw1PTTabHxMuTOkYkL15cbCYiatPIbxdV0zwhfBZKNODg0zFqmbz8f7rKmd6tfR/Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="CsoundAudioNode.js"></script>
<script src="CsoundAC.js"></script>
<script src="silencio/js/TrackballControls.js"></script>
<script src="silencio/js/tinycolor.js"></script>
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="icon" href="data:,">
<style>
</style>
</head>
<body id="body" class="w3-medium" style="height:100vh;">
    <div class="w3-bar w3-dark-grey" style="position:fixed;">    
        <ul class = "menu">
            <li id="menu_item_play" class="w3-btn">Play/stop</li>
            <li id="menu_item_fullscreen" class="w3-btn">Full screen</li>
            <li id="menu_item_settings" class="w3-btn">Settings</li>
            <li id="menu_item_about" class="w3-btn">About</li>
        </ul>
    </div>
    <canvas id="display" class="w3-container" style="background-color:black;height:100%;margin:0;padding:0;">
    </canvas>
    <div id="about_view" class="w3-container" style="position:absolute;top:70px;z-index:3;background:transparent;color:rgba(102,205,170,.5);">
<h1>Cloud Music No. 1</h1>
<h3>Michael Gogins<br>
August 2022</h3>
    
This is an online piece of electroacoustic music. It will play indefinitely, always changing. Visuals accompany the music. There are controls you can play with. If you like your settings, save them.
    
<ul>
<li>To view Csound and JavaScript notifications, use your browser menu to view the JavaScript console.
<li>To view the source code of this piece, use your browser menu to view the page source.
<li>To inspect or debug the code of this piece as it runs, use your browser menu to open the developer tools.
</ul>
    </div>
    <textarea id="csd" cols=80 rows=24 style="display:none;">
<CsoundSynthesizer>
<CsOptions>
-odac -d -m195
</CsOptions>
<CsInstruments> 
; These must all match the host as printed when Csound starts.
sr          =           44100
ksmps       =           128
nchnls      =           2
nchnls_i    =           1

;--------------------------------------------------------
;Instrument 1 : plucked strings chorused left/right and
;       pitch-shifted and delayed taps thru exponential
;       functions, and delayed.
;--------------------------------------------------------

            instr       1
ishift      =           .00666667               ;shift it 8/1200.
ipch        =           cpspch(p5)              ;convert parameter 5 to cps.
ioct        =           octpch(p5)              ;convert parameter 5 to oct.
kvib        poscil      1/120, ipch/50, 1      ;vibrato
ag          pluck       2000, cpsoct(ioct+kvib), 1000, 1, 1
agleft      pluck       2000, cpsoct(ioct+ishift), 1000, 1, 1
agright     pluck       2000, cpsoct(ioct-ishift), 1000, 1, 1
adamping    linsegr     0.0, 0.006, 1.0, p3 - 0.066, 1.0, 0.06, 0.0
ag          =           adamping * ag
agleft      =           adamping * agleft
agright     =           adamping * agright
af1         expon       .1, p3, 1.0             ;exponential from 0.1 to 1.0
af2         expon       1.0, p3, .1             ;exponential from 1.0 to 0.1
adump       delayr      2.0                     ;set delay line of 2.0 sec
atap1       deltap3     af1                     ;tap delay line with kf1 func.
atap2       deltap3     af2                     ;tap delay line with kf2 func.
ad1         deltap3     2.0                     ;delay 2 sec.
ad2         deltap3     1.1                     ;delay 1.1 sec.
            delayw      ag                      ;put ag signal into delay line.
            outs        agleft+atap1+ad1, agright+atap2+ad2
            endin
;-------------------------------------------------------------
;Instrument 2 : plucked strings chorused left/right and
;       pitch-shifted with fixed delayed taps.
;------------------------------------------------------------

            instr       2
ishift      =           .00666667               ;shift it 8/1200.
ipch        =           cpspch(p5)              ;convert parameter 5 to cps.
ioct        =           octpch(p5)              ;convert parameter 5 to oct.
kvib        poscil      1/120, ipch/50, 1       ;vibrato
ag          pluck       1000, cpsoct(ioct+kvib), 1000, 1, 1
agleft      pluck       1000, cpsoct(ioct+ishift), 1000, 1, 1
agright     pluck       1000, cpsoct(ioct-ishift), 1000, 1, 1
adamping    linsegr     0.0, 0.006, 1.0, p3 - 0.066, 1.0, 0.06, 0.0
ag          =           adamping * ag
agleft      =           adamping * agleft
agright     =           adamping * agright
adump       delayr      0.3                     ;set delay line of 0.3 sec
ad1         deltap3     0.1                     ;delay 100 msec.
ad2         deltap3     0.2                     ;delay 200 msec.
            delayw      ag                      ;put ag sign into del line.
            outs        agleft+ad1, agright+ad2
            endin
;-----------------------------------------------------------
;Instrument 3 : New FM algorithm, modified to produce large timbre
;               shifts using modulation of I and r. Detuned chorusing employed.
;-----------------------------------------------------------
            instr       3
ishift      =           .00666667               ;shift it 8/1200.
ipch        =           cpspch(p5)              ;convert parameter 5 to cps.
ioct        =           octpch(p5)              ;convert parameter 5 to oct.
aadsr       linsegr     0, p3/3, 1.0, p3/3, 1.0, p3/3, 0 ;ADSR envelope
amodi       linseg      0, p3/3, 5, p3/3, 3, p3/3, 0 ;ADSR envelope for I
amodr       linseg      p6, p3, p7              ;r moves from p6->p7 in p3 sec.
a1          =           amodi*(amodr-1/amodr)/2
a1ndx       =           abs(a1*2/20)            ;a1*2 is normalized from 0-1.
a2          =           amodi*(amodr+1/amodr)/2
a3          tablei      a1ndx, 3, 1             ;lookup tbl in f3, normal index
ao1         poscil      a1, ipch, 2             ;cosine
a4          =           exp(-0.5*a3+ao1)
ao2         poscil      a2*ipch, ipch, 2        ;cosine
aoutl       poscil      1000*aadsr*a4, ao2+cpsoct(ioct+ishift), 1 ;fnl outleft
aoutr       poscil      1000*aadsr*a4, ao2+cpsoct(ioct-ishift), 1 ;fnl outright
            outs        aoutl, aoutr
            endin

</CsInstruments>
<CsScore>
;       Score for final project in Digital Audio Processing
;       ---------------------------------------------------

;           Piece entitled :  X A N A D U (short version)
;                           Joseph T. Kung, 12/12/88
;            Instruments modified for higher precision
;                         Michael Gogins, 07/22/2006

;           The first part of the score will specify all function
;       tables used in the piece. The second part specifies
;       the instruments and notes. The latter is divided into
;       7 sections, each playing a chord on a different
;                 instrument.
;       The chords are uncommon guitar chords that use the open
;       B and E strings often. These will be transposed by
;       octaves on some chords.

;       Each instrument will play a chord for 15 seconds. The
;                 timbre
;       of the instrument will change in that interval and join
;       with the next instrument/chord sequence. Instrument 3
;       uses a modified FM synthesis technique. This is joined
;       by an additional plucked-string instrument
;       (instruments 1 and 2).
t 0 12
;   The Function Tables
;   -------------------
;All functions are post-normalized (max value is 1) if p4 is
;POSITIVE.

f1 0 65537  10 1      ;sine wave
f2 0 65537  11 1      ;cosine wave
f3 0 65537 -12 20.0  ;unscaled ln(I(x)) from 0 to 20.0

;-----------------------------------------------------------

;----- This section comprises all the new FM sounds -----------

;F#7addB chord on a guitar
i3 0 15 0 7.06 2.0 0.2  ;F#
i3 . . . 8.01 . .   ;C# above
i3 . . . 8.06 . .   ;F# octave above 1st one
i3 . . . 8.10 . .   ;Bb next one up
i3 . . . 8.11 . .   ;B
i3 . . . 9.04 . .   ;E

;D6add9 chord on a guitar
i3 7.5 15 0 6.02 1.7 0.5    ;D
i3 . . . 6.09 . .   ;A above
i3 . . . 7.02 . .   ;D octave above 1st one
i3 . . . 7.06 . .   ;F# next one up
i3 . . . 6.11 . .   ;B
i3 . . . 7.04 . .   ;E

;Bmajadd11 chord on a guitar
i3 15 15 0 7.11 1.4 0.8 ;B
i3 . . . 8.06 . .   ;F# above
i3 . . . 8.11 . .   ;B octave above 1st one
i3 . . . 9.03 . .   ;D# next one up
i3 . . . 8.11 . .   ;B
i3 . . . 9.04 . .   ;E;

;Amajadd9 chord on a guitar
i3 22.5 15 0 6.09 1.1 1.1   ;A
i3 . . . 7.04 . .   ;E above
i3 . . . 8.09 . .   ;A octave above 1st one
i3 . . . 8.01 . .   ;C# next one up
i3 . . . 7.11 . .   ;B
i3 . . . 8.04 . .   ;E

;Bmajadd11 chord on a guitar
i3 30 15 0 6.11 0.8 1.4 ;B
i3 . . . 7.06 . .   ;F# above
i3 . . . 7.11 . .   ;B octave above 1st one
i3 . . . 8.03 . .   ;D# next one up
i3 . . . 7.11 . .   ;B
i3 . . . 8.04 . .   ;E;

;Gmaj6 chord on a guitar
i3 37.5 15 0 5.07 0.5 1.7   ;G
i3 . . . 6.02 . .   ;D above
i3 . . . 6.07 . .   ;G octave above 1st one
i3 . . . 6.11 . .   ;B on G string
i3 . . . 6.11 . .   ;B
i3 . . . 7.04 . .   ;E

;F#7addB chord on a guitar
i3 45 15 0 7.06 0.2 2.0 ;F#
i3 . . . 8.01 . .   ;C# above
i3 . . . 8.06 . .   ;F# octave above 1st one
i3 . . . 8.10 . .   ;Bb next one up
i3 . . . 8.11 . .   ;B
i3 . . . 9.04 . .   ;E

; This section adds the plucked chords to the beginning of each
; section.

;F#7addB chord on a guitar
i1 0 10 0 8.06  ;F#
i1 0.1 . . 9.01 ;C# above
i1 0.2 . . 9.06 ;F# octave above 1st one
i1 0.3 . . 9.10 ;Bb next one up
i1 0.4 . . 9.11 ;B
i1 0.5 . . 10.04    ;E

;D6add9 chord on a guitar
i2 7.5 10 0 8.02    ;D
i2 7.6 . . 8.09     ;A above
i2 7.7 . . 9.02     ;D octave above 1st one
i2 7.8 . . 9.06     ;F# next one up
i2 7.9 . . 9.11     ;B
i2 8.0 . . 10.04    ;E

;Bmajadd11 chord on a guitar
i2 15 10 0 8.11     ;B
i2 15.1 . . 9.06    ;F# above
i2 15.2 . . 9.11    ;B octave above 1st one
i2 15.3 . . 10.03   ;D# next one up
i2 15.4 . . 9.11    ;B
i2 15.5 . . 10.04   ;E;

;Amajadd9 chord on a guitar
i2 22.5 10 0 8.09   ;A
i2 22.6 . . 9.04    ;E above
i2 22.7 . . 10.09   ;A octave above 1st one
i2 22.8 . . 10.01   ;C# next one up
i2 22.9 . . 9.11    ;B
i2 23.0 . . 10.04   ;E

;Bmajadd11 chord on a guitar
i2 30 10 0 8.11     ;B
i2 30.1 . . 9.06    ;F# above
i2 30.2 . . 9.11    ;B octave above 1st one
i2 30.3 . . 10.03   ;D# next one up
i2 30.4 . . 9.11    ;B
i2 30.5 . . 10.04   ;E;

;Gmaj6 chord on a guitar
i2 37.5 10 0 8.07   ;G
i2 37.6 . . 9.02    ;D above
i2 37.7 . . 9.07    ;G octave above 1st one
i2 37.8 . . 9.11    ;B on G string
i2 37.9 . . 9.11    ;B
i2 38.0 . . 10.04   ;E

;F#7addB chord on a guitar
i1 45 10 0 9.06     ;F#
i1 45.1 . . 10.01   ;C# above
i1 45.2 . . 10.06   ;F# octave above 1st one
i1 45.3 . . 10.10   ;Bb next one up
i1 45.4 . . 10.11   ;B
i1 45.5 . . 11.04   ;E
e
</CsScore>
</CsoundSynthesizer>
    </textarea>

    <script id="draw-shader-fs" type="x-shader/x-fragment">
        precision mediump float;
        /**
         * These are all of the standard ShaderToy inputs. If any of these are 
         * used in this shader, they must be created and initialized in the 
         * JavaScript code.
         */
        uniform vec3 iResolution;
        // viewport resolution (in pixels)
        uniform float iTime;
        // shader playback time (in seconds)
        uniform float iTimeDelta;
        // render time (in seconds)
        uniform int iFrame;
        // shader playback frame
        uniform float iChannelTime[4];
        // channel playback time (in seconds)
        uniform vec3 iChannelResolution[4];
        // channel resolution (in pixels)
        uniform vec4 iMouse;
        // mouse pixel coords. xy: current (if MLB down), zw: click
        uniform sampler2D iChannel0;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel1;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel2;
        // input channel. XX = 2D/Cube
        uniform sampler2D iChannel3;
        // input channel. XX = 2D/Cube
        uniform vec4 iDate;
        // (year, month, day, time in seconds)
        uniform float iSampleRate;
        // sound sample rate (i.e., 44100)
        /**
         * These are custom inputs/outputs for music visualization or score 
         * generation.
         */
        uniform float iFftBins[128];
        /** 
         * The FFT bin amplitudes are in [-100, -30], rescale to unity.
         */
        float rescale_bin(float amplitude) {
            amplitude = amplitude + 100.;
            amplitude = amplitude / 70.;
            return amplitude;
        }
         /**
         * Theoretically, any fragment shader copied from the ShaderToy 
         * editor can replace the mainImage function below, if all of the 
         * shader's inputs are defined. https://soundcloud.com/michael-gogins/porphyry-v5?si=1fdbdce77bda4376aabe6e62c28450de
         */
         
        float hash(int x) { return fract(sin(float(x))*7.847); } 

        float dSegment(vec2 a, vec2 b, vec2 c)
        {
            vec2 ab = b-a;
            vec2 ac = c-a;

            float h = clamp(dot(ab, ac)/dot(ab, ab), 0., 1.);
            vec2 point = a+ab*h;
            return length(c-point);
        }

        void mainImage( out vec4 fragColor, in vec2 fragCoord )
        {
            vec2 uv = (fragCoord.xy*2.-iResolution.xy) / iResolution.yy;
            vec3 color = vec3(0.);
            color = mix(vec3(0.325, 0.431, 0.364), color, abs(uv.x)*0.25);
            
            for(int i=0; i < 190; ++i)
            {
                vec2 a = vec2(hash(i)*2.-1., hash(i+1)*2.-1.);
                vec2 b = vec2(hash(10*i+1)*2.-1., hash(11*i+2)*2.-1.);
                vec3 lineColor = vec3(hash(10+i), hash(18+i*3), hash(5+i*10));
                float speed = b.y*0.15;
                float size = (0.005 + 0.3*hash(5+i*i*2)) + (0.5+0.5*sin(a.y*5.+iTime*speed))*0.1;
                
                a += vec2(sin(a.x*20.+iTime*speed), sin(a.y*15.+iTime*0.4*speed)*0.5);
                b += vec2(b.x*5.+cos(iTime*speed), cos(b.y*10.+iTime*2.0*speed)*0.5);
                float dist = dSegment(a, b, uv);

//~ // From https://www.shadertoy.com/view/Xds3Rr. I just need to create and feed this texture.
//~ // create pixel coordinates
//~ vec2 uv = fragCoord.xy / iResolution.xy;

//~ // first texture row is frequency data
//~ float fft  = texture( iChannel0, vec2(uv.x,0.25) ).x; 

//~ // second texture row is the sound wave
//~ float wave = texture( iChannel0, vec2(uv.x,0.75) ).x;

//~ // convert frequency to colors
//~ vec3 col = vec3( fft, 4.0*fft*(1.0-fft), 1.0-fft ) * fft;

//~ // add wave form on top	
//~ col += 1.0 -  smoothstep( 0.0, 0.15, abs(wave - uv.y) );

//~ // output final color
//~ fragColor = vec4(col,1.0);

                float soundWave = .4+texture2D(iChannel0, vec2(uv.x, 0.25)).x;
                color += mix(lineColor, vec3(0.), smoothstep(0., 1.0, pow(dist/size, soundWave*(0.5+0.5*sin(iTime*2.+size+lineColor.x*140.))*0.20) ));
            }
            
            fragColor = vec4(color,1.0);
        }        
        // The main function is just a shim that calls mainImage above.
        void main() 
        {
            mainImage( gl_FragColor, gl_FragCoord.xy );
        }
    </script>

    <script id="draw-shader-vs" type="x-shader/x-vertex">
        attribute vec2 inPos;
        void main() {
            gl_Position = vec4(inPos, 0.0, 1.0);
        }
    </script>
    
   <script> 
        var analyser = null;
        var frequency_domain_data = null;
        var time_domain_data = null;
        const texture_unit_0 = 0;
        (function loadscene() {    
            var canvas;
            var gl;
            var webgl_viewport_size;
            var webgl_buffer_object = {};
            var mouse_position = [0, 0, 0, 0];
            function create_scene() {
                canvas = document.getElementById( "display");
                gl = canvas.getContext( "webgl2" );
                if (!gl) {
                  return;
                }
                canvas.addEventListener('mousemove', (e) => {
                    mouse_position = [e.clientX, e.clientY];
                });
                shader_program = gl.createProgram();
                for (let i = 0; i < 2; ++i) {
                    let shader_code = document.getElementById(i==0 ? "draw-shader-vs" : "draw-shader-fs").text;
                    let shader_object = gl.createShader(i==0 ? gl.VERTEX_SHADER : gl.FRAGMENT_SHADER);
                    gl.shaderSource(shader_object, shader_code);
                    gl.compileShader(shader_object);
                    let status = gl.getShaderParameter(shader_object, gl.COMPILE_STATUS);
                    if (!status) {
                        console.warn(gl.getShaderInfoLog(shader_object));
                    }
                    gl.attachShader(shader_program, shader_object);
                    gl.linkProgram(shader_program);
                }
                status = gl.getProgramParameter(shader_program, gl.LINK_STATUS);
                if (!status) {
                    console.warn(gl.getProgramInfoLog(shader_program));
                }
                shader_program.inPos = gl.getAttribLocation(shader_program, "inPos");
                shader_program.iMouse = gl.getUniformLocation(shader_program, "iMouse");
                shader_program.iResolution = gl.getUniformLocation(shader_program, "iResolution");
                shader_program.iTime = gl.getUniformLocation(shader_program, "iTime");
                shader_program.iTimeDelta = gl.getUniformLocation(shader_program, "iTimeDelta");
                shader_program.iFrame = gl.getUniformLocation(shader_program, "iFrame");
                shader_program.iChannel0 = gl.getUniformLocation(shader_program, "iChannel0");
                shader_program.iChannel1 = gl.getUniformLocation(shader_program, "iChannel1");
                shader_program.iChannel2 = gl.getUniformLocation(shader_program, "iChannel2");
                shader_program.iChannel3 = gl.getUniformLocation(shader_program, "iChannel3");
                shader_program.iFftBins = gl.getUniformLocation(shader_program, "iFftBins");
                gl.useProgram(shader_program);
                /**
                 * We create 4 textures for 4 samplers, to implement the 
                 * ShaderToy channels. The fastest way to get data into and 
                 * out of the shader is to write to and read from the elements 
                 * of the textures in the samplers, using whole arrays or 
                 * element indices (texels). Normally, a loaded image or other 
                 * data is bound to the texture. But here, the textures are 
                 * created with just one pixel and can be filled with data 
                 * later. 
                 */
                /*                
                 // Initial program setup.
                glLinkProgram(program); // Initial link

                GLint baseImageLoc = glGetUniformLocation(program, "baseImage");
                GLint normalMapLoc = glGetUniformLocation(program, "normalMap");
                GLint shadowMapLoc = glGetUniformLocation(program, "shadowMap");

                glUseProgram(program);
                glUniform1i(baseImageLoc, 0); // Texture unit 0 is for base images.
                glUniform1i(normalMapLoc, 2); // Texture unit 2 is for normal maps.
                glUniform1i(shadowMapLoc, 4); // Texture unit 4 is for shadow maps.

                // When rendering an object with this program.
                glActiveTexture(GL_TEXTURE0 + 0);
                glBindTexture(GL_TEXTURE_2D, object1BaseImage);
                glBindSampler(0, linearFiltering);
                glActiveTexture(GL_TEXTURE0 + 2);
                glBindTexture(GL_TEXTURE_2D, object1NormalMap);
                glBindSampler(2, linearFiltering); // Same filtering as before
                glActiveTexture(GL_TEXTURE0 + 4);
                glBindTexture(GL_TEXTURE_2D, shadowMap);
                glBindSampler(4, depthComparison); // Special sampler for depth comparisons.
                */
                const level = 0;
                const internalFormat = gl.RGBA32F;
                const width = 1;
                const height = 1;
                const border = 0;
                const srcFormat = gl.RGBA;
                const srcType = gl.FLOAT;
                const pixels = new Float32Array([0, 0, 255, 255]);  
                gl.activeTexture(gl.TEXTURE0 + texture_unit_0);
                let texture0 = gl.createTexture();
                gl.bindTexture(gl.TEXTURE_2D, texture0);
                gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, width, height, border, srcFormat, srcType, pixels);
                const channel0 = gl.createSampler();
                gl.uniform1i(shader_program.iChannel0, texture_unit_0);
                gl.bindSampler(texture_unit_0, channel0);
                var pos = [ -1, -1, 1, -1, 1, 1, -1, 1 ];
                var inx = [ 0, 1, 2, 0, 2, 3 ];
                webgl_buffer_object.pos = gl.createBuffer();
                gl.bindBuffer( gl.ARRAY_BUFFER, webgl_buffer_object.pos );
                gl.bufferData( gl.ARRAY_BUFFER, new Float32Array( pos ), gl.STATIC_DRAW);
                webgl_buffer_object.inx = gl.createBuffer();
                webgl_buffer_object.inx.len = inx.length;
                gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, webgl_buffer_object.inx );
                gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array( inx ), gl.STATIC_DRAW);
                gl.enableVertexAttribArray(shader_program.inPos);
                gl.vertexAttribPointer(shader_program.inPos, 2, gl.FLOAT, false, 0, 0); 
                gl.enable(gl.DEPTH_TEST);
                gl.clearColor(0.0, 0.0, 0.0, 1.0);
                window.onresize = resize;
                resize();
                requestAnimationFrame(render_scene);
            }

            function resize() {
                webgl_viewport_size = [window.innerWidth, window.innerHeight];
                canvas.width = webgl_viewport_size[0];
                canvas.height = webgl_viewport_size[1];
            }
             function render_scene(delta_milliseconds) {
                if (analyser !== null) {
                    analyser.getFloatFrequencyData(frequency_domain_data);
                    //console.log("frequency_domain_data size: " + frequency_domain_data.length);
                    analyser.getFloatTimeDomainData(time_domain_data);
                    //console.log("time_domain_data: " + time_domain_data);
                    let audio_data = new Float32Array(frequency_domain_data.length + time_domain_data.length);
                    audio_data.set(frequency_domain_data);
                    audio_data.set(time_domain_data, frequency_domain_data.length);
                    //gl.uniform1fv(shader_program.iFftBins, frequency_domain_data);
                    //gl.uniform1fv(shader_program.iChannel0, audio_data);
                    gl.activeTexture(gl.TEXTURE0 + texture_unit_0);
                    // Like: gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, numSamples, 1, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, audioData);
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RED32F, time_domain_data.length, 2, 0, gl.RED, gl.FLOAT, audio_data);
                }
                gl.viewport(0, 0, canvas.width, canvas.height);
                gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
                gl.uniform1f(shader_program.iTime, delta_milliseconds / 1000.0);
                gl.uniform3f(shader_program.iResolution, canvas.width, canvas.height, 0);
                gl.uniform4f(shader_program.iMouse, mouse_position[0], mouse_position[1], 0, 0);
                gl.drawElements(gl.TRIANGLES, webgl_buffer_object.inx.len, gl.UNSIGNED_SHORT, 0);    
                requestAnimationFrame(render_scene);
            }  
            create_scene();
        })();    
    </script>
    <script>
        var message_callback_buffer = "";
        var csound_message_callback = function(message) {
            // Split in case the newline is in the middle of the message but 
            // not at the end?
            message_callback_buffer = message_callback_buffer + message;
            if (message_callback_buffer.endsWith("\n")) {
                console.log(message_callback_buffer);
                message_callback_buffer = "";
            }
        };
        var CsoundAC;
        var csound = null;
        (async function() { 
            CsoundAC = await createCsoundAC(); 
            var txt = "Browser CodeName: " + navigator.appCodeName + "\n";
            txt += "Browser Name: " + navigator.appName + "\n";
            txt += "Browser Version: " + navigator.appVersion + "\n";
            txt += "Cookies Enabled: " + navigator.cookieEnabled + "\n";
            txt += "Browser Language: " + navigator.language + "\n";
            txt += "Browser Online: " + navigator.onLine + "\n";
            txt += "Platform: " + navigator.platform + "\n";
            txt += "User-agent header: " + navigator.userAgent + "\n";
            csound_message_callback(txt);
            csound_message_callback(CsoundAC.chord_space_version() + "\n");
            let CM = CsoundAC.chordForName("C+");
            CM = CM.T(-4.);
            csound_message_callback(CM.information());
            csound_message_callback(CM.information_debug(-1));
        }());
            
        window.onload = function() {
            $("#about_view").css("display", "none");         
            $("#menu_item_play").click(async function(event) {
                console.log("menu_item_play click...");     
                if (csound == null) {
                    try {
                        csound_message_callback("Trying to load CsoundAudioNode...\n");
                        var AudioContext = window.AudioContext || window.webkitAudioContext;
                        var audioContext = new AudioContext();
                        await audioContext.audioWorklet.addModule('CsoundAudioProcessor.js').then(function() {
                            csound_message_callback("Creating CsoundAudioNode...\n");
                            csound_audio_node = new CsoundAudioNode(audioContext, csound_message_callback);
                            csound_message_callback("CsoundAudioNode (AudioWorklet) is available in this JavaScript context.\n");
                            csound = csound_audio_node;
                            console.log("csound: " + csound);
                        }, function(error) {
                           csound_message_callback(error + '\n');
                        });
                    } catch (e) {
                        csound_message_callback(e + '\n');
                    }
                }
                if (csound.is_playing == false) {
                    let csd = await document.getElementById('csd').value;
                    let result = await csound.CompileCsdText(csd);
                    csound_message_callback("CompileCsdText returned: " + result);
                    await csound.Start();
                    await csound.Perform();
                    analyser = new AnalyserNode(audioContext);
                    analyser.fftSize = 1024;
                    const analyzer_buffer_size = analyser.frequencyBinCount;
                    console.log("Analyzer buffer size: " + analyzer_buffer_size);
                    frequency_domain_data = new Float32Array(analyzer_buffer_size);    
                    time_domain_data = new Float32Array(analyzer_buffer_size);    
                    csound.connect(analyser);
                    csound_message_callback("Csound is playing...\n");

                } else {
                    await csound.Stop();
                    await csound.Cleanup();
                    csound.Reset();
                    csound_message_callback("Csound is stopping...\n");
                }
             });
            $("#menu_item_fullscreen").click(function(event) {
                console.log("menu_item_fullscreen click...");
                const display = document.getElementById("display");
                if (display.requestFullscreen) {
                    display.requestFullscreen();
                } else if (display.webkitRequestFullscreen) { 
                    display.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) { 
                    display.msRequestFullscreen();
                }
            });
            $("#menu_item_settings").click(function(event) {
                console.log("menu_item_settings click...");
            });
            $("#menu_item_code").click(function(event) {
                console.log("menu_item_code click...");
             });
            $("#menu_item_notifications").click(function(event) {
                console.log("menu_item_notifications click...");
            });
            $("#menu_item_about").click(function(event) {
                console.log("menu_item_about click...");
                $("#about_view").toggle();            
            });
            $(document).keydown(function(event) {
                console.log("document keydown...");
                if (event.keyCode === 'F11') {
                    $("#menu_item_fullscreen").trigger("click");
                }
            });
        };
    </script>
 </html>
